{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GrrRSZ7IEA18"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "APh82PXP6xkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "id": "7nbYbwcZnvoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4HxeYqs6Amy",
        "outputId": "3a0a3734-f454-4966-e34c-dffe931808f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "S57lo1ganjI_",
        "outputId": "1dfe6d25-1eee-47ee-949c-da93a4590a58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7aab7d74a740>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5f25c122dd6e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Star classification</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Star classification').getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Big data/star_classification.csv\"\n",
        "\n",
        "data = spark.read.csv(path, header=True, inferSchema=True)\n",
        "data.show()\n",
        "\n",
        "data.groupBy(\"class\").count().show()"
      ],
      "metadata": {
        "id": "CsdElq0oC1Hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994b305b-4943-4d67-fb95-b89c1faea849"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------+------------------+--------+--------+--------+--------+--------+------+--------+-------+--------+--------------------+------+------------+-----+-----+--------+\n",
            "|              obj_ID|           alpha|             delta|       u|       g|       r|       i|       z|run_ID|rerun_ID|cam_col|field_ID|         spec_obj_ID| class|    redshift|plate|  MJD|fiber_ID|\n",
            "+--------------------+----------------+------------------+--------+--------+--------+--------+--------+------+--------+-------+--------+--------------------+------+------------+-----+-----+--------+\n",
            "|1.237660961327743...|  135.6891066036|  32.4946318397087|23.87882| 22.2753|20.39501|19.16573|18.79371|  3606|     301|      2|      79|6.543777369295181...|GALAXY|   0.6347936| 5812|56354|     171|\n",
            "|1.237664879951151...|144.826100550256|  31.2741848944939|24.77759|22.83188|22.58444|21.16812|21.61427|  4518|     301|      5|     119|1.176014203670733...|GALAXY|    0.779136|10445|58158|     427|\n",
            "|1.237660961330430...|142.188789562506|  35.5824441819976|25.26307|22.66389|20.60976|19.34857|18.94827|  3606|     301|      2|     120|5.152200256025548...|GALAXY|   0.6441945| 4576|55592|     299|\n",
            "|1.237663478724297...|338.741037753146|-0.402827574587482|22.13682|23.77656|21.61162|20.50454| 19.2501|  4192|     301|      3|     214|1.030107141295442...|GALAXY|   0.9323456| 9149|58039|     775|\n",
            "|1.237680272041378...|345.282593210935|  21.1838656010284|19.43718|17.58028|16.49747|15.97711|15.54461|  8102|     301|      3|     137|6.891864880783317E18|GALAXY|   0.1161227| 6121|56187|     842|\n",
            "|1.237680272039609...|340.995120509191|  20.5894762801019|23.48827|23.33776|21.32195|20.25615|19.54544|  8102|     301|      3|     110|5.658976714552006...|   QSO|    1.424659| 5026|55855|     741|\n",
            "|1.237678858481565...|23.2349264301638|  11.4181876197835|21.46973|21.17624|20.92829|20.60826|20.42573|  7773|     301|      2|     462|  1.2462617271914E19|   QSO|   0.5864546|11069|58456|     113|\n",
            "|1.237678858473963...|5.43317603738404|  12.0651859913473|22.24979|22.02172|20.34126|19.48794|18.84999|  7773|     301|      2|     346|6.961443351364393E18|GALAXY|    0.477009| 6183|56210|      15|\n",
            "|1.237661435386659...|200.290475389797|   47.199402322911|24.40286|22.35669|20.61032| 19.4649|18.95852|  3716|     301|      5|     108|7.459284627188111...|GALAXY|    0.660012| 6625|56386|     719|\n",
            "|1.237670961088168...|39.1496905996484|  28.1028416109607|21.74669|20.03493|19.17553|18.81823|18.65422|  5934|     301|      4|     122|2.751763212482406...|  STAR|-7.895373E-6| 2444|54082|     232|\n",
            "|1.237680272034169...|328.092076173419|  18.2203104791579|25.77163|22.52042|20.63884|19.78071|19.05765|  8102|     301|      3|      27|5.652161941432719...|GALAXY|   0.4595958| 5020|55852|     525|\n",
            "|1.237662341088150...|243.986637469699|  25.7382804319961|23.76761|23.79969|20.98318|19.80745|19.45579|  3927|     301|      4|     112|5.322363975769544...|GALAXY|   0.5914091| 4727|55693|     855|\n",
            "|1.237680507721220...|345.801874402853|  32.6728678500872|23.17274|20.14496|19.41948|19.22034|18.89359|  8157|     301|      2|      38|7.323010883747338...|  STAR| 7.182029E-5| 6504|56540|     574|\n",
            "|1.237678858459349...|331.502029984917|  10.0358020468494| 20.8294|18.75091|17.51118|17.01631|16.62772|  7773|     301|      2|     123|5.702738100025055...|GALAXY|   0.1521936| 5065|55739|     200|\n",
            "|1.237663478726984...|344.984770271278|-0.352615781151814|23.20911|22.79291|22.08589|21.86282| 21.8512|  4192|     301|      3|     255|1.037538657325261...|GALAXY|   0.8181597| 9215|57682|     796|\n",
            "|1.237662341088543...|244.824523050208|  25.1545639915034| 24.8868|22.13311|20.44728|19.49171| 18.9747|  3927|     301|      4|     118|5.322135277350967...|GALAXY|   0.4849288| 4727|55693|      23|\n",
            "|1.237678598087508...|353.201522444633|  3.08079593630972| 24.5489|21.44267|20.95315| 20.7936|20.48442|  7712|     301|      5|     284|4.822278327657322...|  STAR| -4.28576E-4| 4283|55864|     178|\n",
            "|1.237678598091112...|  1.494388639357|  3.29174632998873|20.38562|20.40514|20.29996|20.05918|19.89044|  7712|     301|      5|     339| 9.84382410307275E18|   QSO|    2.031528| 8743|57663|     295|\n",
            "|1.237678598096748...|14.3831352206597|  3.21432619593864|21.82154| 20.5573|19.94918|19.76057|19.55514|  7712|     301|      5|     425|9.855072926793226E18|  STAR|-4.402762E-4| 8753|57373|     258|\n",
            "|1.237651539783057...|167.131668785257|  67.3399356293198|20.48292|18.67807| 17.6168|17.11936|16.73351|  1412|     301|      5|     124|5.518594868731187...|GALAXY|   0.1115879|  490|51929|     613|\n",
            "+--------------------+----------------+------------------+--------+--------+--------+--------+--------+------+--------+-------+--------+--------------------+------+------------+-----+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-----+\n",
            "| class|count|\n",
            "+------+-----+\n",
            "|GALAXY|59445|\n",
            "|   QSO|18961|\n",
            "|  STAR|21594|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "Wf93oH_MK0_q",
        "outputId": "1e5da2bc-587d-4fa7-c2a1-2a7a3290220c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data analysis"
      ],
      "metadata": {
        "id": "RBbAhdVgLyA8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "496bPvz-LxEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data balancing"
      ],
      "metadata": {
        "id": "wn_EfGXTEDEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_count = max(59445, 18961, 21594)\n",
        "\n",
        "# Define fractions for oversampling\n",
        "data_fractions = {\n",
        "    'GALAXY': max_count / 59445,\n",
        "    'QSO': max_count / 18961,\n",
        "    'STAR': max_count / 21594\n",
        "}\n",
        "\n",
        "total_factor = sum(data_fractions.values())\n",
        "data_fractions = {key: value / total_factor for key, value in data_fractions.items()}\n",
        "\n",
        "sampled = data.sampleBy(\"class\", fractions=data_fractions, seed=0)\n",
        "sampled.groupBy(\"class\").count().orderBy(\"class\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyM9dmywQ43K",
        "outputId": "5e542067-4076-4daa-9987-c321091710ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "| class|count|\n",
            "+------+-----+\n",
            "|GALAXY| 8566|\n",
            "|   QSO| 8752|\n",
            "|  STAR| 8667|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "6LIKiI74EL4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_data = data.toPandas()"
      ],
      "metadata": {
        "id": "-tHwtQv_DgH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd_data.drop(['class'], axis = 1)\n",
        "y = pd_data.loc[:,'class'].values\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "x, y = sm.fit_resample(x, y)\n",
        "print('Resampled dataset shape %s' % Counter(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW-Ktnm-ECLY",
        "outputId": "c8dab60e-78fc-4dc0-d279-694063f166a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({'GALAXY': 59445, 'STAR': 21594, 'QSO': 18961})\n",
            "Resampled dataset shape Counter({'GALAXY': 59445, 'QSO': 59445, 'STAR': 59445})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data analysis (balanced dataset)"
      ],
      "metadata": {
        "id": "ehPtwJq3MUca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data preparation"
      ],
      "metadata": {
        "id": "GrrRSZ7IEA18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "x_pd = pd.DataFrame(x)\n",
        "y_pd = pd.DataFrame(y)\n",
        "\n",
        "combined_pd = pd.concat([x_pd, y_pd], axis=1)\n",
        "\n",
        "combined_pd = combined_pd.rename(columns={'0': 'class'})\n",
        "\n",
        "from pyspark.sql import Row\n",
        "\n",
        "combined_df = spark.createDataFrame(combined_pd)\n",
        "\n",
        "train_data, test_data = combined_df.randomSplit([0.8, 0.2], seed=42)\n",
        "train_data.show()\n",
        "\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "dataset_features = ['obj_ID',\n",
        "                    'alpha',\n",
        "                    'delta',\n",
        "                    'u',\n",
        "                    'g',\n",
        "                    'r',\n",
        "                    'i',\n",
        "                    'z',\n",
        "                    'run_ID',\n",
        "                    'rerun_ID',\n",
        "                    'cam_col',\n",
        "                    'field_ID',\n",
        "                    'spec_obj_ID',\n",
        "                    'redshift',\n",
        "                    'plate',\n",
        "                    'MJD',\n",
        "                    'fiber_ID']\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(inputCols=dataset_features,\n",
        "                            outputCol=\"features\")\n",
        "\n",
        "train_data_assembled = assembler.transform(train_data)\n",
        "\n",
        "new_df = train_data_assembled.select(['features','0'])\n",
        "\n",
        "new_df.show()\n",
        "\n",
        "new_df.printSchema()\n",
        "\n",
        "new_df = new_df.withColumnRenamed('0', 'label')\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Lista delle colonne di etichetta\n",
        "label_columns = ['STAR', 'GALAXY ', 'QSO']\n",
        "\n",
        "# Lista delle colonne di etichetta convertite\n",
        "indexed_label_columns = [1,2,3]\n",
        "\n",
        "# Lista per memorizzare gli oggetti StringIndexer\n",
        "indexers = []\n",
        "\n",
        "# Applica StringIndexer a ciascuna colonna di etichetta\n",
        "for label_col, indexed_label_col in zip(label_columns, indexed_label_columns):\n",
        "    indexer = StringIndexer(inputCol=label_col, outputCol=indexed_label_col)\n",
        "    new_df = indexer.fit(new_df).transform(new_df)\n",
        "    indexers.append(indexer)"
      ],
      "metadata": {
        "id": "Fn9OLBefEBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training phase"
      ],
      "metadata": {
        "id": "5fnZK83hEKK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "lr.setLabelCol('0')\n",
        "lrModel = lr.fit(new_df)\n",
        "\n",
        "# Print the coefficients and intercept for logistic regression\n",
        "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
        "print(\"Intercept: \" + str(lrModel.intercept))"
      ],
      "metadata": {
        "id": "x6vV8yU6EKUd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}